{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Part 2: Dataset + Data Collection\n",
    "\n",
    "## Overview\n",
    "\n",
    "Based on the feedback you received from your lightning talk, choose **one** of your topic areas to move forward. For Part 2, you'll need to collect, clean, and document the dataset(s) you intend to use for your project.\n",
    "\n",
    "This is not always a trivial task. Remember that data acquisition, transformation, and cleaning are typically the most time-consuming parts of data science projects, so don’t procrastinate!\n",
    "\n",
    "Once you have your data, read into it and review it to confirm whether it is as productive as you intended. If not, switch datasets, gather additional data (e.g. multiple datasets), or revise your project goals.\n",
    "\n",
    "Create your own database and data dictionary, then clean and munge your data as appropriate. Finally, document your work so far.\n",
    "\n",
    "**Goal**: Find the data you need for your project, clean, and document it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. Find and Clean Your Data: Source and format the required data for your project.\n",
    "   - Create a database\n",
    "   - Create a data dictionary\n",
    "2. Perform preliminary data munging and cleaning of your data: organize your data relevant to your project goals.\n",
    "   - Review data to verify initial assumptions\n",
    "   - Clean and munge data as necessary\n",
    "3. Describe your data: keep your intended audience(s) in mind.\n",
    "   - Document your work so far in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lewis/opt/anaconda3/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am sourcing my data by webscraping pets4homes.co.uk. My goal is to scrape information for each current listing for a dog. Time permitting, I may also go back and scrape all cat listings too.\n",
    "\n",
    "To source the data I will need conduct two rounds a webscraping. The first round will loop through each page of search results and access the url associated with each listing. After removing any duplicates returned by this scrape, I will use the scraped urls to view each listing and scrape it's relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# temp - for developing code\n",
    "\n",
    "path = '/Users/lewis/Desktop/Pets4homes_html.rtf'\n",
    "\n",
    "with open(path) as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.pets4homes.co.uk/classifieds/yr3fb2k-p-american-xl-bullys-derby/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/vyty6c1dk-minature-sproodles-both-parents-dna-health-tested-ludlow/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/z1oexw0ee-beautiful-pocket-bully-york/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/nkagacnp6-4-minature-black-cream-tan-puppies-for-sale-saint-austell/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/zs49btlds-xl-bully-puppies-enzo-bossy-huntingdon/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/ki82wcwyi-beautiful-blue-pomeranian-girl-wednesbury/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/lxvob6o3u-french-bulldog-puppies-5-weeks-old-wigston/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/svdoywp2-bosipoos-winchester/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/dldyzmqdc-f1-goldendoodle-puppies-available-18th-feb-wrexham/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/jlhv6nwjw-beautiful-shihpoochon-puppies-for-sale-llanelli/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/d2n2uy9kw-new-shade-isabella-and-tan-boy-london/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/mzgkoimkf-american-akita-puppies-for-sale-bradford/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/ujo1a2vei-chunky-akita-puppies-birmingham/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/kiuscobt4-brand-new-litter-today-swanley/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/pbozefifk-english-bulldog-kc-registered-chocolate-and-lilac-hemel-hempstead/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/b3l8soaw7-gorgeous-f1-apricot-cockapoo-puppies-reading/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/iby6o6nr4-st90ar-stoke-on-trent/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/tearpcb3s-only-4-females-left-husky-puppies-walsall/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/4bxfoz3qp-golden-retriever-puppies-due-in-a-weeks-time-northampton/',\n",
       " 'https://www.pets4homes.co.uk/classifieds/5wc940pnd-merle-cane-corso-pups-stockton-on-tees/']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to extract urls from search pages\n",
    "\n",
    "def get_url(page):\n",
    "    \n",
    "    cur_page_listing_urls = []\n",
    "\n",
    "    for a in page.find_all('a', class_=\"cb Um\"):\n",
    "        url = 'https://www.pets4homes.co.uk' + a['href']\n",
    "        if url in cur_page_listing_urls:\n",
    "            continue\n",
    "        else:\n",
    "            cur_page_listing_urls.append(url)\n",
    "    \n",
    "    return cur_page_listing_urls\n",
    "\n",
    "get_url(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "# getting dogs urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "for page_num in range(1,501):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/puppies/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "dogs = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "dogs = pd.DataFrame(dogs, columns = ['URLs'])\n",
    "\n",
    "# exporting to csv\n",
    "dogs.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/dogs_ulrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "# getting cats urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "for page_num in range(1,224):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/kittens/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "cats = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "cats = pd.DataFrame(cats, columns = ['URLs'])\n",
    "\n",
    "# exporting to csv\n",
    "cats.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/cat_ulrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/bhhhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/n-9id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/yblc-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/umi4g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/b4ei5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  https://www.pets4homes.co.uk/classifieds/bhhhe...\n",
       "1  https://www.pets4homes.co.uk/classifieds/n-9id...\n",
       "2  https://www.pets4homes.co.uk/classifieds/yblc-...\n",
       "3  https://www.pets4homes.co.uk/classifieds/umi4g...\n",
       "4  https://www.pets4homes.co.uk/classifieds/b4ei5..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/dog_ulrs.csv',\n",
    "                   index_col='Unnamed: 0')\n",
    "dogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.pets4homes.co.uk/classifieds/bhhhealt0-beautiful-pups-looking-for-forever-homes-sittingbourne/']\n"
     ]
    }
   ],
   "source": [
    "print(dogs.iloc[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/lwbo0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/d32lj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/gdgkk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/51nyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/3izse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  https://www.pets4homes.co.uk/classifieds/lwbo0...\n",
       "1  https://www.pets4homes.co.uk/classifieds/d32lj...\n",
       "2  https://www.pets4homes.co.uk/classifieds/gdgkk...\n",
       "3  https://www.pets4homes.co.uk/classifieds/51nyb...\n",
       "4  https://www.pets4homes.co.uk/classifieds/3izse..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/cat_ulrs.csv',\n",
    "                   index_col='Unnamed: 0')\n",
    "cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "\n",
    "4. Document your project goals (revise from your initial pitch)\n",
    "   - Articulate “Specific aim”\n",
    "   - Outline proposed methods and models\n",
    "   - Define risks & assumptions\n",
    "\n",
    "5. Create a blog post of at least 500 words that describes your work so far. Link to it in your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Deliverable Format & Submission\n",
    "\n",
    "- Table, file, or database with relevant text file or notebook description.\n",
    "\n",
    "---\n",
    "\n",
    "## Suggested Ways to Get Started\n",
    "\n",
    "- Review your initial proposal topic and feedback, and revise accordingly.\n",
    "- Spend time with your data and verify that it can help you accomplish the goals you set out to pursue.\n",
    "- If not, document how you intend to either change those goals.\n",
    "- Alternatively, go find some additional data and/or try another source.\n",
    "\n",
    "---\n",
    "\n",
    "## Useful Resources\n",
    "\n",
    "- [Exploratory Data Analysis](http://insightdatascience.com/blog/eda-and-graphics-eli-bressert.html)\n",
    "- [Best practices for data documentation](https://www.dataone.org/all-best-practices)\n",
    "\n",
    "---\n",
    "\n",
    "## Project Feedback + Evaluation\n",
    "\n",
    "[Attached here is a complete rubric for this project.](./capstone-part-02-rubric.md)\n",
    "\n",
    "Your instructors will score each of your technical requirements using the scale below:\n",
    "\n",
    "Score  | Expectations\n",
    "--- | ---\n",
    "**0** | _Incomplete._\n",
    "**1** | _Does not meet expectations._\n",
    "**2** | _Meets expectations, good job!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
